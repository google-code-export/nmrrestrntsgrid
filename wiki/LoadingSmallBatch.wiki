#summary Doc for how to load a small batch of entries (e.g. oceans12)
#labels Phase-Deploy

= Entry set =

`1a24 1a4d 1afp 1ai0 1brv 1bus 1cjg 1hue 1ieh 1iv6 1kr8 2hgh 2k0e`

= PHASE - Prep =
Make sure you work under the development settings. Execute:

swNRG31

and check that your classpath starts with the correct jar with:
{{{
wsetup
echo $CLASSPATH
/big/docr/workspace/wattos/lib/Wattos.jar....
}}}
If it's the one in /share you need to change something caus that's production.


Now, empty the tables of the DEVELOPMENT database.

The production database is wattos2. The development is wattos1. The user name
is always the same as the database name.

Login to the mysql database to remove spurious entries:
{{{
mysql -h localhost -u wattos1 -p4I4KMS wattos1
}}}

BEFORE YOU CONTINUE, look at the nice data online in NRG we have in production and develop.
Make sure that after you do the next step only the development has been touched!
It takes a long time before I can restore the production site completely. Perhaps
as much as a week!

To remove all:
{{{
delete from entry;
}}}

= PHASE 1 Original =
One can copy the annotated .mr files from tang in /share/wattos/mr_anno_backup
to the in progress dir and do them one by one.

Type:
{{{
set x = 1a4d
scp /share/wattos/mr_anno_backup/$x.mr \
     /dumpzone/pdb/mr_anno_progress_nrg31
wsetup
mrannotator
}}}  

When that gets old, do the bulk loading using a script in Wattos project/scripts:
{{{
cd '/Users/jd/CloneWars/DOCR1000/oceans12/bmrb/' # where .mr files are located.
}}}
I have another copy on tang: 
{{{cd/big/jurgen/oceans12/bmrb}}}
Note the list of the random 100 resides in:
{{{
/big/jurgen/random100/list.csv
}}}

Then edit
$WS/wattos/scripts/load_db_raw.csh


= PHASE 2 Parsed =

Assuming the above has been set.

Look up the script:
$WS/wattos/scripts/load_db_conversions.csh

Run the java command inside once to see if it works for one small entry (may
I suggest 1a24?). If it works for one it should work for all. 
Note that even though the script is called something with 'conversions' it
results in the data being at the PHASE 2: Parsed.

= PHASE 3 and 4 - Converted and Filtered. =

Assuming the above has been set.
Look up the modified well-known script:
$WS/nmrrestrntsgrid/scripts/processDOCR_FRED.csh

First check again if you have the development settings for the nmrrestrntsgrid
project. The scripts_dir variable now needs to point to $WS/nmrrestrntsgrid/scripts.
WS stands for the workspace directory on /big/docr.

Do:
{{{
echo $scripts_dir
}}}
and ensure it points to  point to $WS/nmrrestrntsgrid/scripts.

The way you run it hasn't changed:
{{{
set x = 1a4d  ; $scripts_dir/processDOCR_FRED.csh $x |& tee $perEntry_dir/$x.log
cat $dir_star/$x/$x.log
}}}

Check he NRG results: http://tang.bmrb.wisc.edu/NRG/MRGridServlet

Check in the usual way with the script weeklyDOCR_FRED.csh.

==NB==
  * Don't do the 'whole/weekly' set yet.
  * Recall that the script will fail with "No input STAR parsed restraints file:
{{{
/big/docr/NRG/restraint/unzipped/1a4d_rst.str
}}}
If they haven't been retrieved with the weekly script -first-.
  * The log file for the FC step is in $ccpn_tmp_dir/data/recoord/$x
  * The CCPN xml .tgz is not in the database because of reported issue: 42.
  * There is a new header that still needs to be ok-ed by all. 
  * I will switch the redirection at www.bmrb.wisc.edu to this version when we're all ready.
  * Entry 2k0e takes the FC about 35 minutes if a cpu is available even after the ensemble is truncated to a max of 7500 residues total.
* Entries that need to have settings corrected by annotation:
        * 1cjg 1iv6 2hgh 2k0e (issue 76)
* We need to ensure we exclude entries that are going to kill the server such as 2k0e did (issue 66). This is one reason we can't do the whole batch yet.
* Consider that the presetDict.py needs to be brought up to date. Issue (issue 76) correspondence.

Now go ahead and try putting all 13 in. Five entries will fail yet.